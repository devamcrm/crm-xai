import streamlit as st
from pathlib import Path

# ---------- Page Config ----------
st.set_page_config(
    page_title="How This Study Works",
    layout="wide"
)

# ---------- Logo ----------
ASSETS_DIR = Path(__file__).resolve().parent.parent / "assets"
LOGO_PATH = ASSETS_DIR / "uol_logo.svg"

st.image(str(LOGO_PATH), width=160)
st.markdown("---")

# ---------- Page Title ----------
st.title("How This Study Works")

st.markdown("""
This page explains **what you will see**, **what you will be asked to do**,  
and **how your interaction with the system contributes to the research**.
""")

# ---------- Overview ----------
st.header("Overview of the experience")

st.markdown("""
You will be guided through a **structured, step-by-step experience** involving
two versions of a CRM recommendation system.

The goal is to understand how **explainability** affects:
- Trust in AI recommendations
- Confidence in using AI outputs
- Perceived usefulness in a business context
""")

# ---------- Step-by-step ----------
st.header("Step-by-step flow")

st.subheader("1. Context and customer data")

st.markdown("""
You will first see a **simplified and anonymised customer data context**.
This represents the type of behavioural and transactional signals
commonly used in CRM systems, such as:
- Purchase history
- Engagement patterns
- Category preferences

No real customer data is used.
All data shown in this application is **synthetic or anonymised**.
""")

st.subheader("2. Black-box recommendation experience")

st.markdown("""
You will be shown a recommendation generated by a model **without any explanation**.

This reflects how many real-world AI systems operate today, where:
- A recommendation is provided
- The internal reasoning of the model is hidden

After viewing this recommendation, you will be asked to share your views on:
- How much you trust the recommendation
- How confident you feel using it
- Whether you would act on it in a real business setting
""")

st.subheader("3. Explainable recommendation experience")

st.markdown("""
You will then see a recommendation generated by the **same underlying model**,
but this time accompanied by **clear explanations**.

These explanations use **SHAP (SHapley Additive exPlanations)** to show:
- Which factors influenced the recommendation
- How strongly each factor contributed
- Whether each factor pushed the recommendation up or down

The recommendation itself may be similar or identical â€”
the key difference is **transparency**.
""")

st.subheader("4. Comparison and reflection")

st.markdown("""
After experiencing both versions, you will be asked to **compare them** and reflect on:
- Which version you trusted more
- Whether explanations increased your confidence
- How explainability would affect your willingness to adopt AI tools at work
""")

# ---------- Important notes ----------
st.header("Important notes")

st.markdown("""
- There are **no right or wrong answers**
- The study focuses on your **professional judgement and perception**
- You may skip any question you do not wish to answer
- Your responses are used **only for academic research**
""")

# ---------- Data & ethics ----------
st.header("Use of your responses")

st.markdown("""
Any information you share within this application will be used **strictly for research purposes**
and will be governed by the information provided in the
**Participant Information Sheet**.

You may revisit this information at any time.
""")

st.page_link(
    "pages/1_Participant_Information.py",
    label="ðŸ“„ View Participant Information Sheet",
    use_container_width=False
)

st.markdown("---")

st.info(
    "When you are ready, please continue to the next page to learn more about the data used in this study."
)
